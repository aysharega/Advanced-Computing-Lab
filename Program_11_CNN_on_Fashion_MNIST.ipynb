{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Program 11:CNN on Fashion_MNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMJvjrQYUYMml1X4FwnmFHR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aysharega/Advanced-computing-Lab/blob/master/Program_11_CNN_on_Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqjF8DETM8eW"
      },
      "source": [
        "#**CNN** on Fashion_MNIST Dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZsBpVSo5MdWD",
        "outputId": "9ceba6f7-8e8e-4ace-a0df-a75920ffd08a"
      },
      "source": [
        "#CNN on Fashion_MNIST\n",
        "#Training dataset-60000, testing- 10000 28x28 grayscale images(10 classes)\n",
        "#1. Load and process Fashion_MNIST\n",
        "from tensorflow import keras\n",
        "fashion_mnistDB = keras.datasets.fashion_mnist\n",
        "(Xtrain, Ytrain),(Xtest, Ytest)=fashion_mnistDB.load_data()\n",
        "print(\"X_train Size: \", Xtrain.shape)\n",
        "print(\"X_test Size: \", Xtest.shape)\n",
        "print(\"Y_train Size: \", Ytrain.shape)\n",
        "print(\"Y_test Size: \", Ytest.shape)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(Xtrain[250], cmap='binary')\n",
        "plt.imshow(Xtrain[200], cmap='binary')\n",
        "#1b. Conversion to 1 channel\n",
        "Xtrain =Xtrain.reshape((60000,28,28,1))\n",
        "Xtest =Xtest.reshape((10000,28,28,1))\n",
        "print(\"New X_train Size: \", Xtrain.shape)\n",
        "print(\"New X_test Size: \", Xtest.shape)\n",
        "#1c. Normalize\n",
        "Xtrain =Xtrain.astype('float32')/255\n",
        "Xtest =Xtest.astype('float32')/255\n",
        "#2. Create CNN layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "cnn = keras.models.Sequential()\n",
        "cnn.add(keras.layers.Conv2D(32,(3,3), activation = \"relu\", input_shape=Xtrain.shape[1:]))\n",
        "cnn.add(keras.layers.Conv2D(64,(3,3),activation = \"relu\"))\n",
        "cnn.add(keras.layers.MaxPool2D(2,2))\n",
        "cnn.add(keras.layers.Dropout(0.25))\n",
        "cnn.add(keras.layers.Flatten())\n",
        "cnn.add(keras.layers.Dense(128, activation = \"relu\"))\n",
        "cnn.add(keras.layers.Dropout(0.25))\n",
        "cnn.add(keras.layers.Dense(10, activation = \"softmax\"))\n",
        "cnn.summary()\n",
        "#3. Compile and test\n",
        "cnn.compile(loss=\"sparse_categorical_crossentropy\", \n",
        "            optimizer=\"adam\", metrics=\"accuracy\")\n",
        "\n",
        "\n",
        "es=keras.callbacks.EarlyStopping(monitor='loss',patience=10,restore_best_weights=True)\n",
        "cp=keras.callbacks.ModelCheckpoint( \"/content/CNN_MNIST.h5\",monitor='val_loss')\n",
        "cnn.fit(Xtrain,Ytrain, epochs=2, batch_size=16,callbacks=[es,cp])\n",
        "test_loss, test_accuracy = cnn.evaluate (Xtest, Ytest)\n",
        "print (\"Test_Loss=\", test_loss)\n",
        "print (\"Test_Accuracy=\", test_accuracy)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "X_train Size:  (60000, 28, 28)\n",
            "X_test Size:  (10000, 28, 28)\n",
            "Y_train Size:  (60000,)\n",
            "Y_test Size:  (10000,)\n",
            "New X_train Size:  (60000, 28, 28, 1)\n",
            "New X_test Size:  (10000, 28, 28, 1)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "3750/3750 [==============================] - 199s 53ms/step - loss: 0.4003 - accuracy: 0.8557\n",
            "Epoch 2/2\n",
            "3750/3750 [==============================] - 197s 52ms/step - loss: 0.2627 - accuracy: 0.9030\n",
            "313/313 [==============================] - 7s 21ms/step - loss: 0.2460 - accuracy: 0.9100\n",
            "Test_Loss= 0.24595783650875092\n",
            "Test_Accuracy= 0.9100000262260437\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}